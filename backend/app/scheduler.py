from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
import asyncio
import os
import datetime
import httpx
import logging
import shlex
from .database import SessionLocal
from . import models

scheduler = AsyncIOScheduler()
logger = logging.getLogger(__name__)

# å…¨å±€å­—å…¸å­˜å‚¨è¿è¡Œä¸­çš„è¿›ç¨‹: script_id -> subprocess.Process
RUNNING_TASKS = {}

async def notify_telegram(message: str, bot_token: str, chat_id: str):
    if not bot_token or not chat_id:
        return
    
    # è·å–ä»£ç†é…ç½®
    db = SessionLocal()
    proxy_setting = db.query(models.Setting).filter(models.Setting.key == "tg_proxy").first()
    proxy = proxy_setting.value if proxy_setting and proxy_setting.value else None
    db.close()

    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
    
    # httpx proxy å‚æ•°
    proxies = proxy if proxy else None
    
    logger.info(f"Sending TG message via proxy: {proxies}")
    async with httpx.AsyncClient(proxy=proxies) as client:
        try:
            await client.post(url, json={"chat_id": chat_id, "text": message})
        except Exception as e:
            logger.error(f"Failed to send TG notification: {e}")

async def stop_script(script_id: int):
    """åœæ­¢æ­£åœ¨è¿è¡Œçš„è„šæœ¬"""
    import signal

    if script_id not in RUNNING_TASKS:
        logger.warning(f"Script {script_id} not found in RUNNING_TASKS")
        return False

    try:
        process = RUNNING_TASKS[script_id]

        # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦ä»åœ¨è¿è¡Œ
        if process.returncode is not None:
            logger.info(f"Script {script_id} already finished with code {process.returncode}")
            return True

        # è·å–è¿›ç¨‹ç»„ID (ç­‰äºè¿›ç¨‹PIDï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨äº† start_new_session=True)
        pgid = process.pid

        # å‘é€ SIGTERM åˆ°æ•´ä¸ªè¿›ç¨‹ç»„ï¼Œä¸€æ¬¡æ€§ç»ˆæ­¢æ‰€æœ‰å­è¿›ç¨‹
        logger.info(f"Sending SIGTERM to process group {pgid} for script {script_id}")
        try:
            os.killpg(pgid, signal.SIGTERM)
        except ProcessLookupError:
            logger.info(f"Process group {pgid} already terminated")
            return True

        # ç­‰å¾…è¿›ç¨‹ç»“æŸï¼Œæœ€å¤š3ç§’
        try:
            await asyncio.wait_for(process.wait(), timeout=3.0)
            logger.info(f"Script {script_id} terminated gracefully")
            return True
        except asyncio.TimeoutError:
            # å¼ºåˆ¶æ€æ­»æ•´ä¸ªè¿›ç¨‹ç»„
            logger.warning(f"Script {script_id} did not terminate, sending SIGKILL to process group")
            try:
                os.killpg(pgid, signal.SIGKILL)
            except ProcessLookupError:
                pass
            try:
                await asyncio.wait_for(process.wait(), timeout=2.0)
            except Exception as kill_err:
                logger.error(f"Error force killing script {script_id}: {kill_err}")
            return True
    except Exception as e:
        logger.error(f"Error stopping script {script_id}: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        return False

async def run_script(script_id: int, script_path: str, script_name: str, bot_token: str = None, chat_id: str = None, arguments: str = None, is_daemon: bool = False):
    # å‡†å¤‡æ—¥å¿—æ–‡ä»¶ - å°½æ—©åˆ›å»ºï¼Œç¡®ä¿èƒ½è®°å½•æ‰€æœ‰é”™è¯¯
    log_dir = "/data/logs"
    os.makedirs(log_dir, exist_ok=True)
    log_file_path = os.path.join(log_dir, f"{script_id}.log")
    start_time = datetime.datetime.now()

    # ç«‹å³åˆ›å»º/æ›´æ–°æ—¥å¿—æ–‡ä»¶ï¼Œè®°å½•å¯åŠ¨ä¿¡æ¯
    with open(log_file_path, "a") as log_file:
        log_file.write(f"\n\n{'='*20} Starting at {start_time} {'='*20}\n")
        log_file.flush()

    # å¦‚æœå·²ç»åœ¨è¿è¡Œï¼Œå…ˆä¸é‡å¤å¯åŠ¨ï¼ˆæˆ–è€…æ˜¯é‡å¯ï¼Ÿè¿™é‡Œç­–ç•¥æ˜¯å•å®ä¾‹è¿è¡Œï¼‰
    if script_id in RUNNING_TASKS:
        if RUNNING_TASKS[script_id].returncode is None:
            logger.warning(f"Script {script_name} is already running.")
            with open(log_file_path, "a") as log_file:
                log_file.write(f"Error: Script is already running, skipped.\n")
            return

    logger.info(f"Starting script: {script_name} (Daemon: {is_daemon})")

    db = SessionLocal()
    script = db.query(models.Script).filter(models.Script.id == script_id).first()
    if script:
        script.last_status = "running"
        script.last_run = start_time
        db.commit()

    try:
        # æ£€æŸ¥è„šæœ¬æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(script_path):
            raise FileNotFoundError(f"Script file not found: {script_path}")

        # æ„å»ºå‘½ä»¤
        cmd_args = []
        if script_path.endswith('.py'):
            program = "python3"
            # å¼ºåˆ¶ Python åˆ·æ–°ç¼“å†²åŒºï¼Œä¿è¯å®æ—¶æ—¥å¿—
            cmd_args.append("-u")
            cmd_args.append(script_path)
        else:
            # ä½¿ç”¨ stdbuf å¼ºåˆ¶è¡Œç¼“å†²ï¼Œä¿è¯ shell è„šæœ¬å®æ—¶è¾“å‡ºæ—¥å¿—
            program = "stdbuf"
            cmd_args.extend(["-oL", "-eL", "bash", script_path])

        if arguments:
            args_list = shlex.split(arguments)
            cmd_args.extend(args_list)

        logger.info(f"Executing command: {program} {' '.join(cmd_args)}")

        # è®°å½•æ‰§è¡Œå‘½ä»¤åˆ°æ—¥å¿—
        with open(log_file_path, "a") as log_file:
            log_file.write(f"Command: {program} {' '.join(cmd_args)}\n")
            log_file.flush()
            
        # å¯åŠ¨è¿›ç¨‹ï¼Œé‡å®šå‘ stdout å’Œ stderr åˆ° PIPE
        # ä½¿ç”¨ start_new_session=True åˆ›å»ºæ–°çš„è¿›ç¨‹ç»„ï¼Œä¾¿äºä¸€æ¬¡æ€§ç»ˆæ­¢æ‰€æœ‰å­è¿›ç¨‹
        process = await asyncio.create_subprocess_exec(
            program, *cmd_args,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.STDOUT,  # åˆå¹¶ stderr åˆ° stdout
            start_new_session=True  # åˆ›å»ºæ–°ä¼šè¯/è¿›ç¨‹ç»„
        )
        
        RUNNING_TASKS[script_id] = process

        # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶å¤§å°ï¼Œå¦‚æœè¶…è¿‡ 2MB åˆ™æˆªæ–­ï¼ˆä¿ç•™æœ€åä¸€éƒ¨åˆ†æˆ–æ¸…ç©ºï¼Œç®€å•èµ·è§æ¸…ç©ºæ—§çš„ï¼‰
        if os.path.exists(log_file_path) and os.path.getsize(log_file_path) > 2 * 1024 * 1024:
            with open(log_file_path, "w") as f:
                f.write(f"=== Log rotated at {start_time} ===\n")

        # å®æ—¶è¯»å–æ—¥å¿—å¹¶å†™å…¥æ–‡ä»¶ (ä½¿ç”¨è¿½åŠ æ¨¡å¼)
        with open(log_file_path, "a", buffering=1) as log_file: # Line buffering
            log_file.write(f"Process started (PID: {process.pid})\n")
            
            while True:
                line = await process.stdout.readline()
                if not line:
                    break
                decoded_line = line.decode('utf-8', errors='replace')
                log_file.write(decoded_line)
                # å¯ä»¥åœ¨è¿™é‡Œåš WebSocket å¹¿æ’­ï¼Œä½†æ›´ç®€å•çš„æ˜¯å‰ç«¯é€šè¿‡ WS è¯»å–æ–‡ä»¶
        
        await process.wait()
        
        # è¿›ç¨‹ç»“æŸ
        return_code = process.returncode
        status = "success" if return_code == 0 else "failed"
        if return_code == -15: # SIGTERM
            status = "stopped"

        # å†æ¬¡å†™å…¥ç»“æŸæ ‡è®°
        with open(log_file_path, "a") as log_file:
            log_file.write(f"\n=== Finished at {datetime.datetime.now()} with status: {status} ===\n")

        # æ›´æ–°æ•°æ®åº“
        # éœ€è¦é‡æ–°åˆ›å»º sessionï¼Œå› ä¸ºä¹‹å‰çš„ session å¯èƒ½å¤ªä¹…äº†
        db.close()
        db = SessionLocal()
        script = db.query(models.Script).filter(models.Script.id == script_id).first()
        if script:
            script.last_status = status
            # è¯»å–æœ€åçš„æ—¥å¿—å­˜å…¥ last_output (ä¸ºäº†å†å²æŸ¥çœ‹)
            try:
                with open(log_file_path, "r") as f:
                    # åªå­˜æœ€å 5000 å­—ç¬¦åˆ°æ•°æ®åº“
                    f.seek(0, 2)
                    size = f.tell()
                    f.seek(max(size - 5000, 0))
                    script.last_output = f.read()
            except:
                pass
            db.commit()
            
        logger.info(f"Script {script_name} finished with status: {status}")

        if bot_token and chat_id and not is_daemon:
            # æ£€æŸ¥æ˜¯å¦ä»…å¤±è´¥æ—¶é€šçŸ¥
            notify_on_failure_only_setting = db.query(models.Setting).filter(
                models.Setting.key == "tg_notify_on_failure_only"
            ).first()
            notify_on_failure_only = notify_on_failure_only_setting and notify_on_failure_only_setting.value == 'true'

            # å¦‚æœå¼€å¯äº†ä»…å¤±è´¥é€šçŸ¥ï¼Œä¸”çŠ¶æ€æ˜¯æˆåŠŸï¼Œåˆ™è·³è¿‡é€šçŸ¥
            if notify_on_failure_only and status == "success":
                logger.info(f"Skipping success notification for {script_name} (notify_on_failure_only enabled)")
            else:
                msg = f"ğŸš€ è„šæœ¬: {script_name}\nçŠ¶æ€: {status}\nè€—æ—¶: {datetime.datetime.now() - start_time}"
                await notify_telegram(msg, bot_token, chat_id)
            
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        logger.error(f"Error running script {script_name}: {e}\n{error_details}")
        # å†™å…¥é”™è¯¯æ—¥å¿—
        with open(log_file_path, "a") as log_file:
            log_file.write(f"\n=== Internal Error ===\n")
            log_file.write(f"Error: {e}\n")
            log_file.write(f"Details:\n{error_details}\n")
            log_file.flush()

        # æ›´æ–°æ•°æ®åº“çŠ¶æ€
        try:
            db.rollback()  # å›æ»šå¯èƒ½çš„æœªæäº¤äº‹åŠ¡
            script = db.query(models.Script).filter(models.Script.id == script_id).first()
            if script:
                script.last_status = "failed"
                db.commit()
        except Exception as db_err:
            logger.error(f"Failed to update script status: {db_err}")
    finally:
        if script_id in RUNNING_TASKS:
            del RUNNING_TASKS[script_id]
        db.close()

def update_scheduler(script_id, cron_expr, script_path, script_name, bot_token=None, chat_id=None, arguments=None):
    job_id = f"script_{script_id}"
    if scheduler.get_job(job_id):
        scheduler.remove_job(job_id)
    
    # å¦‚æœæ˜¯ @daemonï¼Œä¸æ·»åŠ åˆ°å®šæ—¶å™¨ï¼Œåªç”¨äºæ ‡è®°
    if cron_expr == "@daemon":
        return

    if cron_expr:
        try:
            scheduler.add_job(
                run_script,
                CronTrigger.from_crontab(cron_expr),
                id=job_id,
                args=[script_id, script_path, script_name, bot_token, chat_id, arguments, False]
            )
        except Exception as e:
            logger.error(f"Failed to add cron job for {script_name}: {e}")

async def health_check():
    issues = []
    db = SessionLocal()
    
    # è·å– TG é…ç½®ç”¨äºé€šçŸ¥
    proxy_setting = db.query(models.Setting).filter(models.Setting.key == "tg_proxy").first()
    token_setting = db.query(models.Setting).filter(models.Setting.key == "tg_bot_token").first()
    chat_setting = db.query(models.Setting).filter(models.Setting.key == "tg_chat_id").first()
    
    token = token_setting.value if token_setting else None
    chat_id = chat_setting.value if chat_setting else None
    
    # 1. æ£€æŸ¥å¸¸é©»è„šæœ¬
    # æŸ¥æ‰¾æ•°æ®åº“ä¸­è®¤ä¸ºæ˜¯ 'running' ä¸”æ˜¯ daemon çš„è„šæœ¬
    running_daemons = db.query(models.Script).filter(
        models.Script.last_status == 'running', 
        models.Script.cron == '@daemon'
    ).all()
    
    for script in running_daemons:
        # æ£€æŸ¥ RUNNING_TASKS ä¸­æ˜¯å¦å­˜åœ¨ä¸”å­˜æ´»
        proc = RUNNING_TASKS.get(script.id)
        is_alive = False
        if proc and proc.returncode is None:
            is_alive = True
            
        if not is_alive:
            script.last_status = 'failed'
            issues.append(f"ğŸ”´ å®ˆæŠ¤è„šæœ¬ [{script.name}] æ„å¤–åœæ­¢")
            logger.warning(f"Health Check: Daemon script {script.name} found dead. Updating status to failed.")
            
    db.commit()
    db.close()
    
    if issues and token and chat_id:
        msg = "ğŸ¥ *å¥åº·æ£€æŸ¥è­¦æŠ¥*\n\n" + "\n".join(issues)
        await notify_telegram(msg, token, chat_id)
    
    return issues